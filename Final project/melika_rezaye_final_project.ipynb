{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"FINAL PROJECT :","metadata":{"id":"SoBDbUQC-e7f"}},{"cell_type":"markdown","source":"This project fine-tunes a pre-trained VGG16 model on the MNIST handwritten digits dataset.\nThe dataset is split into 70% training, 20% validation, and 10% testing.\nThe last three fully connected layers of VGG16 are concatenated and fed into a new fully connected layer for classification.\nThe model is trained with different hyperparameter settings (learning rate, batch size, optimizer type) to achieve the highest F1-score on the validation set.","metadata":{"id":"kX25ZQ-v-uhg"}},{"cell_type":"markdown","source":"import libraries :","metadata":{"id":"30mTyzxJ-n27"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.metrics import f1_score","metadata":{"id":"XRK44K0X-W8k","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:16.803321Z","iopub.execute_input":"2025-10-05T17:39:16.804014Z","iopub.status.idle":"2025-10-05T17:39:24.286390Z","shell.execute_reply.started":"2025-10-05T17:39:16.803987Z","shell.execute_reply":"2025-10-05T17:39:24.285818Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Prepare the MNIST Dataset :\n\nHere, the MNIST dataset is prepared and transformed to 3-channel 224Ã—224 images (as required by VGG16).","metadata":{"id":"Un4r-_5v_C1Q"}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.Grayscale(3),\n    transforms.ToTensor(),\n])\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset  = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)","metadata":{"id":"GqPYFpkW_FXP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f9937a88-53fe-4b83-f763-b9e52f9eddae","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:24.287416Z","iopub.execute_input":"2025-10-05T17:39:24.287766Z","iopub.status.idle":"2025-10-05T17:39:34.577386Z","shell.execute_reply.started":"2025-10-05T17:39:24.287740Z","shell.execute_reply":"2025-10-05T17:39:34.576521Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:01<00:00, 5.50MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 160kB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.89MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"split dataset :\n\nHere,the MNIST dataset splits into 70% training, 20% validation, and 10% testing sets.","metadata":{"id":"2I1hyoDa_l5P"}},{"cell_type":"code","source":"full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\ntotal_len = len(full_dataset)\ntrain_len = int(0.7 * total_len)\nvalid_len = int(0.2 * total_len)\ntest_len  = total_len - train_len - valid_len\ntrain_set, valid_set, test_set = random_split(full_dataset, [train_len, valid_len, test_len])","metadata":{"id":"d-BSO1Ys_XvO","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.578192Z","iopub.execute_input":"2025-10-05T17:39:34.578468Z","iopub.status.idle":"2025-10-05T17:39:34.588663Z","shell.execute_reply.started":"2025-10-05T17:39:34.578449Z","shell.execute_reply":"2025-10-05T17:39:34.588067Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Create DataLoaders :","metadata":{"id":"kKM7nmN__7G4"}},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nvalid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)\ntest_loader  = DataLoader(test_set,  batch_size=64, shuffle=False)","metadata":{"id":"QhrFRBRx_6Lm","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.590430Z","iopub.execute_input":"2025-10-05T17:39:34.590846Z","iopub.status.idle":"2025-10-05T17:39:34.596653Z","shell.execute_reply.started":"2025-10-05T17:39:34.590827Z","shell.execute_reply":"2025-10-05T17:39:34.595992Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Define the Modified VGG16 Architecture :\n\nThis section modifies the VGG16 model.\nThe outputs of its three fully connected layers are concatenated and fed into a new fully connected layer that classifies the 10 MNIST classes.","metadata":{"id":"tKIAx_NxAJ3-"}},{"cell_type":"code","source":"import torchvision.models as models\n\nclass ModifiedVGG16(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ModifiedVGG16, self).__init__()\n        vgg = models.vgg16(pretrained=True)\n\n        self.features = vgg.features\n        self.avgpool = vgg.avgpool\n\n        fc1 = vgg.classifier[0]\n        fc2 = vgg.classifier[3]\n        fc3 = vgg.classifier[6]\n\n        self.fc1 = fc1\n        self.relu1 = nn.ReLU(inplace=True)\n        self.drop1 = vgg.classifier[2]\n\n        self.fc2 = fc2\n        self.relu2 = nn.ReLU(inplace=True)\n        self.drop2 = vgg.classifier[5]\n\n        self.fc3 = fc3\n\n        self.final_fc = nn.Linear(4096 + 4096 + 1000, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n\n        out1 = self.drop1(self.relu1(self.fc1(x)))\n        out2 = self.drop2(self.relu2(self.fc2(out1)))\n        out3 = self.fc3(out2)\n\n        concat_out = torch.cat([out1, out2, out3], dim=1)\n        final_out = self.final_fc(concat_out)\n\n        return final_out","metadata":{"id":"7V7xmLnkAKHH","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.597515Z","iopub.execute_input":"2025-10-05T17:39:34.597777Z","iopub.status.idle":"2025-10-05T17:39:34.612586Z","shell.execute_reply.started":"2025-10-05T17:39:34.597750Z","shell.execute_reply":"2025-10-05T17:39:34.611907Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Define Training function :\n\ntrains the model for one epoch and returns F1 and loss.","metadata":{"id":"0Prezd5NAYPo"}},{"cell_type":"code","source":"def train_one_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0\n    all_preds, all_labels = [], []\n\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        preds = torch.argmax(outputs, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n    for i, (images, labels) in enumerate(loader):\n      if i % 100 == 0:\n        print(f\"Batch {i}/{len(loader)} done\")\n    return running_loss / len(loader), f1","metadata":{"id":"uyBwKJcFAYo2","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.613212Z","iopub.execute_input":"2025-10-05T17:39:34.613453Z","iopub.status.idle":"2025-10-05T17:39:34.630806Z","shell.execute_reply.started":"2025-10-05T17:39:34.613431Z","shell.execute_reply":"2025-10-05T17:39:34.630068Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Define Evaluation Functions :\n\ncomputes validation or test loss and F1 score without updating the weights.","metadata":{"id":"RqyQNuvbAviY"}},{"cell_type":"code","source":"def evaluate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n\n            preds = torch.argmax(outputs, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n    return running_loss / len(loader), f1","metadata":{"id":"GLswteg-A7zP","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.631444Z","iopub.execute_input":"2025-10-05T17:39:34.631606Z","iopub.status.idle":"2025-10-05T17:39:34.639669Z","shell.execute_reply.started":"2025-10-05T17:39:34.631592Z","shell.execute_reply":"2025-10-05T17:39:34.639021Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Training Loop with Hyperparameter Tuning :\n\nThis function runs a complete training experiment with customizable hyperparameters (learning rate, batch size, optimizer, epochs).\nIt saves the best model based on validation F1 score.","metadata":{"id":"AMXVdoYpBGj3"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef run_experiment(lr=1e-4, batch_size=64, epochs=5, optimizer_type=\"adam\"):\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n\n    model = ModifiedVGG16(num_classes=10).to(device)\n    criterion = nn.CrossEntropyLoss()\n\n    if optimizer_type == \"adam\":\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    elif optimizer_type == \"sgd\":\n        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n    else:\n        raise ValueError(\"Unsupported optimizer\")\n\n    best_f1 = 0\n    for epoch in range(epochs):\n        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        valid_loss, valid_f1 = evaluate(model, valid_loader, criterion, device)\n\n        if valid_f1 > best_f1:\n            best_f1 = valid_f1\n            best_model = model.state_dict()\n\n        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f}, F1: {train_f1:.4f} | Valid Loss: {valid_loss:.4f}, F1: {valid_f1:.4f}\")\n\n    torch.save(best_model, \"best_vgg16_mnist.pth\")\n    return best_f1\n","metadata":{"id":"vbaOhbjwBG5f","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.640313Z","iopub.execute_input":"2025-10-05T17:39:34.640515Z","iopub.status.idle":"2025-10-05T17:39:34.714116Z","shell.execute_reply.started":"2025-10-05T17:39:34.640490Z","shell.execute_reply":"2025-10-05T17:39:34.713341Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Try Different Hyperparameter Combinations :\n\nThis part runs multiple experiments with different hyperparameter combinations and reports the one that achieves the highest F1-score.","metadata":{"id":"JojSBpSQBtmc"}},{"cell_type":"code","source":"results = {}\nfor lr in [1e-3]:\n    for bs in [32, 64]:\n        for opt in [\"adam\", \"sgd\"]:\n            print(f\"\\nðŸ”¹ Running exp: lr={lr}, bs={bs}, opt={opt}\")\n            f1 = run_experiment(lr=lr, batch_size=bs, epochs=5, optimizer_type=opt)\n            results[(lr, bs, opt)] = f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtfmvhS7Bt5d","outputId":"66207f42-1b5f-456a-af5a-6d93ef4a1c4c","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:39:34.714838Z","iopub.execute_input":"2025-10-05T17:39:34.715025Z","iopub.status.idle":"2025-10-05T20:29:45.842772Z","shell.execute_reply.started":"2025-10-05T17:39:34.715003Z","shell.execute_reply":"2025-10-05T20:29:45.841968Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Running exp: lr=0.001, bs=32, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:02<00:00, 210MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 2.3160, F1: 0.0880 | Valid Loss: 2.3024, F1: 0.0209\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 2.3042, F1: 0.0767 | Valid Loss: 2.3018, F1: 0.0209\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 2.3043, F1: 0.0760 | Valid Loss: 2.3012, F1: 0.0209\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 2.3038, F1: 0.0672 | Valid Loss: 2.3022, F1: 0.0209\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 2.3037, F1: 0.0626 | Valid Loss: 2.3016, F1: 0.0209\n\nðŸ”¹ Running exp: lr=0.001, bs=32, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 0.0808, F1: 0.9735 | Valid Loss: 0.0267, F1: 0.9915\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 0.0201, F1: 0.9937 | Valid Loss: 0.0214, F1: 0.9934\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 0.0123, F1: 0.9962 | Valid Loss: 0.0273, F1: 0.9925\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 0.0092, F1: 0.9969 | Valid Loss: 0.0203, F1: 0.9953\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 0.0059, F1: 0.9981 | Valid Loss: 0.0199, F1: 0.9945\n\nðŸ”¹ Running exp: lr=0.001, bs=64, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 0.3429, F1: 0.8890 | Valid Loss: 0.1303, F1: 0.9601\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.0883, F1: 0.9739 | Valid Loss: 0.0710, F1: 0.9788\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.0682, F1: 0.9794 | Valid Loss: 0.0428, F1: 0.9863\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.0569, F1: 0.9828 | Valid Loss: 0.0475, F1: 0.9861\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.0492, F1: 0.9860 | Valid Loss: 0.0448, F1: 0.9868\n\nðŸ”¹ Running exp: lr=0.001, bs=64, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 0.1024, F1: 0.9664 | Valid Loss: 0.0256, F1: 0.9923\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.0220, F1: 0.9928 | Valid Loss: 0.0282, F1: 0.9914\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.0143, F1: 0.9955 | Valid Loss: 0.0196, F1: 0.9943\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.0109, F1: 0.9966 | Valid Loss: 0.0226, F1: 0.9936\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.0072, F1: 0.9976 | Valid Loss: 0.0203, F1: 0.9948\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import json\nimport os\n\nresults_json = {f\"lr={k[0]}_bs={k[1]}_opt={k[2]}\": v for k, v in results.items()}\n\nfile_path = \"results.json\"\n\nif os.path.exists(file_path):\n    with open(file_path, \"r\") as f:\n        try:\n            existing_data = json.load(f)\n        except json.JSONDecodeError:\n            existing_data = {}\nelse:\n    existing_data = {}\n\nexisting_data.update(results_json)\nwith open(file_path, \"w\") as f:\n    json.dump(existing_data, f, indent=2)\n\nprint(\"âœ… Results appended to results.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T20:33:12.875999Z","iopub.execute_input":"2025-10-05T20:33:12.876788Z","iopub.status.idle":"2025-10-05T20:33:12.882791Z","shell.execute_reply.started":"2025-10-05T20:33:12.876761Z","shell.execute_reply":"2025-10-05T20:33:12.882151Z"}},"outputs":[{"name":"stdout","text":"âœ… Results appended to results.json\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"results = {}\n\nfor lr in [1e-4, 1e-5]:\n    for bs in [32, 64]:\n        for opt in [\"adam\", \"sgd\"]:\n            print(f\"\\nðŸ”¹ Running exp: lr={lr}, bs={bs}, opt={opt}\")\n            f1 = run_experiment(lr=lr, batch_size=bs, epochs=5, optimizer_type=opt)\n            results[(lr, bs, opt)] = f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T20:34:32.098797Z","iopub.execute_input":"2025-10-05T20:34:32.099068Z","iopub.status.idle":"2025-10-06T02:15:22.946062Z","shell.execute_reply.started":"2025-10-05T20:34:32.099048Z","shell.execute_reply":"2025-10-06T02:15:22.945147Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Running exp: lr=0.0001, bs=32, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 0.0724, F1: 0.9783 | Valid Loss: 0.0586, F1: 0.9821\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 0.0316, F1: 0.9906 | Valid Loss: 0.0420, F1: 0.9869\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 0.0230, F1: 0.9938 | Valid Loss: 0.0310, F1: 0.9915\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 0.0200, F1: 0.9942 | Valid Loss: 0.0295, F1: 0.9916\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 0.0188, F1: 0.9945 | Valid Loss: 0.0276, F1: 0.9925\n\nðŸ”¹ Running exp: lr=0.0001, bs=32, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 0.1641, F1: 0.9468 | Valid Loss: 0.0403, F1: 0.9879\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 0.0401, F1: 0.9877 | Valid Loss: 0.0316, F1: 0.9903\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 0.0288, F1: 0.9905 | Valid Loss: 0.0275, F1: 0.9915\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 0.0208, F1: 0.9929 | Valid Loss: 0.0260, F1: 0.9919\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 0.0174, F1: 0.9943 | Valid Loss: 0.0205, F1: 0.9940\n\nðŸ”¹ Running exp: lr=0.0001, bs=64, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 0.0729, F1: 0.9779 | Valid Loss: 0.0270, F1: 0.9924\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.0242, F1: 0.9925 | Valid Loss: 0.0299, F1: 0.9921\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.0215, F1: 0.9942 | Valid Loss: 0.0246, F1: 0.9931\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.0163, F1: 0.9955 | Valid Loss: 0.0291, F1: 0.9914\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.0122, F1: 0.9965 | Valid Loss: 0.0306, F1: 0.9926\n\nðŸ”¹ Running exp: lr=0.0001, bs=64, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 0.2744, F1: 0.9135 | Valid Loss: 0.0539, F1: 0.9827\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.0565, F1: 0.9820 | Valid Loss: 0.0386, F1: 0.9879\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.0395, F1: 0.9874 | Valid Loss: 0.0338, F1: 0.9890\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.0318, F1: 0.9899 | Valid Loss: 0.0286, F1: 0.9910\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.0271, F1: 0.9913 | Valid Loss: 0.0269, F1: 0.9916\n\nðŸ”¹ Running exp: lr=1e-05, bs=32, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 0.0923, F1: 0.9722 | Valid Loss: 0.0266, F1: 0.9916\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 0.0179, F1: 0.9946 | Valid Loss: 0.0197, F1: 0.9938\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 0.0111, F1: 0.9964 | Valid Loss: 0.0191, F1: 0.9946\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 0.0071, F1: 0.9978 | Valid Loss: 0.0201, F1: 0.9943\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 0.0052, F1: 0.9985 | Valid Loss: 0.0259, F1: 0.9939\n\nðŸ”¹ Running exp: lr=1e-05, bs=32, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [1/5] | Train Loss: 0.7511, F1: 0.7695 | Valid Loss: 0.1528, F1: 0.9572\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [2/5] | Train Loss: 0.1464, F1: 0.9550 | Valid Loss: 0.0854, F1: 0.9742\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [3/5] | Train Loss: 0.0996, F1: 0.9685 | Valid Loss: 0.0674, F1: 0.9794\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [4/5] | Train Loss: 0.0785, F1: 0.9747 | Valid Loss: 0.0560, F1: 0.9831\nBatch 0/1532 done\nBatch 100/1532 done\nBatch 200/1532 done\nBatch 300/1532 done\nBatch 400/1532 done\nBatch 500/1532 done\nBatch 600/1532 done\nBatch 700/1532 done\nBatch 800/1532 done\nBatch 900/1532 done\nBatch 1000/1532 done\nBatch 1100/1532 done\nBatch 1200/1532 done\nBatch 1300/1532 done\nBatch 1400/1532 done\nBatch 1500/1532 done\nEpoch [5/5] | Train Loss: 0.0685, F1: 0.9782 | Valid Loss: 0.0506, F1: 0.9841\n\nðŸ”¹ Running exp: lr=1e-05, bs=64, opt=adam\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 0.1125, F1: 0.9659 | Valid Loss: 0.0268, F1: 0.9915\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.0200, F1: 0.9939 | Valid Loss: 0.0220, F1: 0.9934\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.0115, F1: 0.9961 | Valid Loss: 0.0191, F1: 0.9943\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.0066, F1: 0.9978 | Valid Loss: 0.0226, F1: 0.9933\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.0051, F1: 0.9985 | Valid Loss: 0.0214, F1: 0.9939\n\nðŸ”¹ Running exp: lr=1e-05, bs=64, opt=sgd\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Batch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [1/5] | Train Loss: 1.1467, F1: 0.6490 | Valid Loss: 0.3339, F1: 0.9244\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [2/5] | Train Loss: 0.2640, F1: 0.9212 | Valid Loss: 0.1407, F1: 0.9616\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [3/5] | Train Loss: 0.1569, F1: 0.9518 | Valid Loss: 0.1002, F1: 0.9705\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [4/5] | Train Loss: 0.1209, F1: 0.9624 | Valid Loss: 0.0818, F1: 0.9755\nBatch 0/766 done\nBatch 100/766 done\nBatch 200/766 done\nBatch 300/766 done\nBatch 400/766 done\nBatch 500/766 done\nBatch 600/766 done\nBatch 700/766 done\nEpoch [5/5] | Train Loss: 0.1004, F1: 0.9681 | Valid Loss: 0.0709, F1: 0.9776\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import json\nimport os\n\nresults_json = {f\"lr={k[0]}_bs={k[1]}_opt={k[2]}\": v for k, v in results.items()}\n\nfile_path = \"results.json\"\n\nif os.path.exists(file_path):\n    with open(file_path, \"r\") as f:\n        try:\n            existing_data = json.load(f)\n        except json.JSONDecodeError:\n            existing_data = {}\nelse:\n    existing_data = {}\n\nexisting_data.update(results_json)\n\nwith open(file_path, \"w\") as f:\n    json.dump(existing_data, f, indent=2)\n\nprint(\"âœ… Results appended to results.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T02:30:31.902838Z","iopub.execute_input":"2025-10-06T02:30:31.903658Z","iopub.status.idle":"2025-10-06T02:30:31.910198Z","shell.execute_reply.started":"2025-10-06T02:30:31.903626Z","shell.execute_reply":"2025-10-06T02:30:31.909556Z"}},"outputs":[{"name":"stdout","text":"âœ… Results appended to results.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import json\n\nfile_path = \"results.json\"\n\n# Load all results from the JSON file\nwith open(file_path, \"r\") as f:\n    all_results = json.load(f)\n\n# Find best config\nbest_config = max(all_results, key=all_results.get)\nbest_f1 = all_results[best_config]\n\nprint(\"Best config:\", ' '.join(best_config.split('_')), \"with F1:\", best_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T02:33:26.205489Z","iopub.execute_input":"2025-10-06T02:33:26.205764Z","iopub.status.idle":"2025-10-06T02:33:26.211377Z","shell.execute_reply.started":"2025-10-06T02:33:26.205745Z","shell.execute_reply":"2025-10-06T02:33:26.210594Z"}},"outputs":[{"name":"stdout","text":"Best config: lr=0.001 bs=32 opt=sgd with F1: 0.9952765989922462\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30TGqKd8UwfN","outputId":"6960f8bd-935e-4a7f-e54c-5330a878a268","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T02:31:16.158960Z","iopub.execute_input":"2025-10-06T02:31:16.159246Z","iopub.status.idle":"2025-10-06T02:31:16.163712Z","shell.execute_reply.started":"2025-10-06T02:31:16.159225Z","shell.execute_reply":"2025-10-06T02:31:16.162963Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}